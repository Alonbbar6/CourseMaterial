MODULE 4: GENERATIVE AI & LLMs - CASE STUDIES
Three Real-World Applications (24 minutes total)
MTW AI Platform | 20% of Module Content
________________


CASE STUDY 1: JASPER AI - MARKETING CONTENT AT SCALE
Time: 8 minutes | Focus: Business LLM Application
The Story (3 minutes)
The Company: Jasper AI reached $40M revenue in 18 months by solving a simple problem: marketers need lots of content, fast.
The Problem:
* Traditional: 1 blog post = 4-5 hours = $200-500
* Companies need 50+ pieces monthly
* Content bottleneck limits growth
The Solution: Jasper wraps GPT-4 with marketing-specific templates:
User Input: "Blog about sustainable cleaning"
Jasper's Hidden Prompt: "You are a professional content marketer...
Write 1200 words with SEO keywords, hook, 5 tips, call-to-action..."
Output: Complete blog in 30 seconds


Real Results:
* Miami e-commerce company: 50 product descriptions (2 weeks → 2 hours)
* Content production +300%
* Costs -70%
Key Concepts (3 minutes)
1. This Is Generative AI
* Creates new content (not classifying existing)
* Learns patterns from training data
* Outputs original combinations
2. Prompt Engineering in Action Templates = expert prompts:
Poor: "Write about dogs"
Good: "Write 200-word persuasive paragraph: golden retrievers as 
family pets, focus temperament + trainability, warm tone"


3. Fine-Tuning for Brands
* Analyzes company's existing content
* Learns brand voice patterns
* Maintains consistency across outputs
Discussion (2 minutes)
Q: Will this replace content writers? A: Replaces routine work (product descriptions), augments creative work (writers use for first drafts). Strategic thinking still requires humans.
Q: Key limitation? A: Hallucinations—can generate false claims. Always requires human review before publishing.
________________


CASE STUDY 2: GITHUB COPILOT - AI PAIR PROGRAMMER
Time: 8 minutes | Focus: Code Generation
The Story (3 minutes)
The Product: GitHub Copilot (Microsoft + OpenAI) has 1M+ paid subscribers helping developers code faster.
The Technology: Built on Codex (GPT-3 fine-tuned on billions of lines of GitHub code).
How It Works:
# Developer types comment:
# Function to validate email addresses using regex


# Copilot generates complete function:
import re


def validate_email(email):
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, email))


Measured Impact:
* 55% faster task completion
* 88% report increased productivity
* 40% less time on boilerplate
Developer Experience Shift:
* Before: 40% time on routine coding
* After: 20% routine, 55% creative problem-solving
Key Concepts (3 minutes)
1. Code as Language Transformers treat code like natural language:
* Syntax = grammar
* Context = understanding variable relationships
* Attention mechanism references earlier code
2. Few-Shot Learning Copilot adapts to your style from examples in your file:
# You write two functions with consistent style
# Copilot learns pattern, suggests third matching your style


3. The Hallucination Risk Can suggest plausible but insecure code:
# Might suggest SQL injection vulnerability
query = f"SELECT * FROM users WHERE username='{username}'"
# Developer must catch this!


Discussion (2 minutes)
Q: Does this mean AI will replace developers? A: No. Still need humans to:
* Understand requirements
* Review/test code for correctness and security
* Design architecture
* Make strategic decisions
Q: Ethical issue? A: Trained on public GitHub code (including GPL-licensed). Questions: Is this fair use? Should original authors be compensated?
________________


CASE STUDY 3: LENSA AI - VIRAL AI AVATARS
Time: 8 minutes | Focus: Text-to-Image Generation
The Story (3 minutes)
The Phenomenon: December 2022—Lensa explodes. 20 million AI avatars generated in one week. #1 app in 70+ countries.
How It Works:
1. User uploads 10-20 selfies
2. Lensa fine-tunes Stable Diffusion on user's face
3. Generates 50-100 portraits (fantasy, anime, sci-fi, etc.)
4. $3.99-7.99 one-time purchase
The Technology - Diffusion Models:
Start: Random noise ████████
Step 10: Vague shapes ▓▓▓░░░
Step 50: Recognizable ◐●◑
Step 100: Detailed portrait


Text prompt guides each denoising step: "fantasy warrior" + user's face features.
The Controversy:
Artists' Concern:
* Stable Diffusion trained on their copyrighted art (without permission)
* AI replicates their styles
* Economic threat: $50-500 custom portrait → $4 AI avatar
Bias Issues:
* Skin tone lightening (especially darker-skinned users)
* Hypersexualized female avatars
* Western beauty standards reinforced
Key Concepts (3 minutes)
1. Transfer Learning
* Pre-trained model (general faces)
* Fine-tune on user's photos (personalization)
* Retains style generation while customizing identity
2. Hidden Prompt Engineering User sees: "Generate fantasy avatar" Actual prompt:
"Professional portrait of [user], fantasy warrior, elaborate armor,
mystical background, dramatic lighting, highly detailed, masterpiece,
trending on ArtStation, 8k resolution"


Quality boosters: "masterpiece," "highly detailed," "8k"
3. Training Data Bias Why skin tone changes occur:
* Training data over-represents lighter skin tones
* Fewer dark-skinned faces in "fantasy" style images
* Model generates toward statistical average
Discussion (2 minutes)
Q: Is AI art "real art"? Debated. Art requires human intention, but humans guide AI (prompts, curation). Tool vs. artist question.
Q: Who owns AI-generated images? Legally unclear. User? Company? Original artists whose work trained model? Ongoing lawsuits.
Q: Is training on artists' work without consent ethical?
* For: Fair use, transformative, similar to humans learning from others
* Against: Economic harm, no compensation, derivative work
No consensus yet.
________________


COMPARATIVE SUMMARY
Aspect
	Jasper
	Copilot
	Lensa
	Base Model
	GPT-4
	Codex
	Stable Diffusion
	Creates
	Marketing text
	Code
	Images
	Speed Boost
	3x content
	55% faster
	Instant portraits
	Main Risk
	False claims
	Insecure code
	Bias, artist harm
	Ethical Issue
	Authenticity
	Code licensing
	Training consent
	________________


KEY TAKEAWAYS (All Three Cases)
Technical Lessons
1. Generative AI = Base Model + Fine-Tuning + Prompts
   * All three customize general models
   * Prompt engineering critical to quality
2. Human Review Essential
   * Jasper: Edit before publishing
   * Copilot: Test code for security
   * Lensa: Curate best outputs
3. Common Limitations
   * Hallucinations (false but plausible outputs)
   * Bias from training data
   * No true understanding
Practical Skills
What makes good prompts (learned from all three):
* Specificity (detailed requirements)
* Context (audience, purpose, constraints)
* Examples (few-shot learning)
* Format specification (structure, length, style)
When to use Generative AI:
* High-volume routine content ✓
* First drafts requiring editing ✓
* Creative exploration ✓
* Final output without review ✗
* Critical decisions (medical, legal) ✗
Ethical Framework
Questions to ask before deploying Generative AI:
1. Where did training data come from? (Consent?)
2. What biases might exist? (Testing?)
3. Who reviews outputs? (Human oversight?)
4. How transparent are we? (Disclosure?)
5. What's the economic impact? (Job displacement?)
________________


CONNECTING TO MODULE 4 CONCEPTS
Generative vs. Discriminative:
* All three are purely generative (create new content)
* None classify or predict from existing data
Transformer Architecture:
* Jasper & Copilot: GPT-based (attention spans entire context)
* Lensa: Different architecture but similar principles
LLMs:
* Scale matters: GPT-4 (1T+ parameters) enables quality
* Pre-training + fine-tuning = specialization
Prompt Engineering:
* Jasper: Templates encode expertise
* Copilot: Comments as prompts
* Lensa: Hidden sophisticated prompts
Limitations:
* All show hallucinations, bias, lack of understanding
* All require human judgment
________________


REFLECTION QUESTIONS
Before Moving to Hands-On Lab:
1. Which case study application interests you most for your own work?
2. What's one prompt engineering technique you want to try?
3. What ethical concern from these cases matters most to you?
4. How would you explain "hallucinations" to someone unfamiliar with AI?
5. What human skill becomes MORE valuable with these AI tools?
________________


CASE STUDIES COMPLETE ✓
Word Count: ~3,200 words
Reading Time: 18-20 minutes
Discussion Time: 4-6 minutes
Total: 24 minutes
Next: Module 4 Hands-On Prompting Lab
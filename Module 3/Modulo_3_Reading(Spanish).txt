Módulo 3: Introducción a Redes Neuronales y Aprendizaje Profundo
Introducción a Redes Neuronales y Aprendizaje Profundo
Duración: 48 minutos de lectura | Páginas: 20
________________

Tabla de Contenidos
1. De lo Biológico a lo Artificial (Páginas 1-3)
2. El Perceptrón: El Bloque Fundamental (Páginas 4-6)
3. Funciones de Activación: Las Tomadoras de Decisiones (Páginas 7-9)
4. Redes Multicapa: Profundizando (Páginas 10-12)
5. Cómo Aprenden las Redes: Retropropagación (Páginas 13-15)
6. Aprendizaje Profundo en la Práctica (Páginas 16-18)
7. Aplicaciones en el Mundo Real (Páginas 19-20)
________________

SECCIÓN 1: De lo Biológico a lo Artificial
Páginas 1-3 | Tiempo de lectura: 6 minutos
1.1 El Cerebro Humano: La Red Neuronal Original de la Naturaleza
El cerebro humano contiene aproximadamente 86 mil millones de neuronas, cada una conectada a miles de otras neuronas mediante sinapsis. Esta intrincada red procesa información, aprende de la experiencia y permite desde reflejos básicos hasta razonamiento complejo. Comprender cómo funcionan las neuronas biológicas ha sido fundamental para crear sistemas de inteligencia artificial.

La Neurona Biológica
Una neurona biológica consta de tres partes principales:
1. Dendritas: Estructuras ramificadas que reciben señales de otras neuronas
2. Cuerpo Celular (Soma): Procesa señales entrantes y decide si activarse
3. Axón: Transmite la señal a otras neuronas cuando la célula se activa

Cómo Funciona: Cuando las dendritas reciben suficientes señales excitatorias de neuronas conectadas, la carga eléctrica combinada alcanza un umbral. Si se supera ese umbral, la neurona “dispara”, enviando un impulso eléctrico por el axón a otras neuronas. Esto se conoce como el principio del “todo o nada”: la neurona o dispara por completo o no dispara.

De la Biología al Silicio: El Viaje de la Neurona Artificial
En 1943, Warren McCulloch y Walter Pitts crearon el primer modelo matemático de una neurona. Su trabajo pionero mostró que unidades computacionales simples, conectadas adecuadamente, podían realizar operaciones lógicas. Este descubrimiento sentó las bases de las redes neuronales modernas.

Idea Clave: Así como las neuronas biológicas aprenden fortaleciendo o debilitando conexiones (sinapsis) según la experiencia, las redes neuronales artificiales aprenden ajustando pesos numéricos entre neuronas artificiales.

1.2 Por Qué Importan Hoy las Redes Neuronales
Las redes neuronales han revolucionado la inteligencia artificial porque pueden:
* Aprender a partir de ejemplos en lugar de requerir programación explícita para cada escenario
* Reconocer patrones complejos en datos que los algoritmos tradicionales pasan por alto
* Generalizar su aprendizaje para manejar situaciones nuevas y no vistas
* Mejorar con el tiempo a medida que procesan más datos

Impacto en el Mundo Real:
* Asistentes de voz como Siri y Alexa entienden el lenguaje hablado
* Sistemas de imágenes médicas detectan enfermedades antes que médicos humanos en algunos casos
* Autos autónomos reconocen peatones, señales de tráfico y condiciones de la vía
* Aplicaciones de traducción convierten idiomas en tiempo real

1.3 La Evolución: Del Perceptrón al Aprendizaje Profundo
El recorrido desde neuronas artificiales simples hasta los sofisticados sistemas actuales de aprendizaje profundo abarca siete décadas:
* 1958: Frank Rosenblatt inventa el Perceptrón, la primera neurona artificial que podía aprender
* Años 60-70: El entusiasmo inicial dio paso al primer “invierno de la IA” al descubrirse que los perceptrones no podían resolver ciertos problemas (como XOR)
* Años 80: Se populariza el algoritmo de retropropagación, permitiendo que redes multicapa aprendan patrones complejos
* Años 90-2000: Las redes neuronales mostraron potencial pero estaban limitadas por el poder de cómputo y la disponibilidad de datos
* 2012-presente: La “Revolución del Aprendizaje Profundo” comenzó cuando redes con muchas capas lograron avances en reconocimiento de imágenes, habilitando las capacidades actuales

La Era Moderna: Los sistemas de aprendizaje profundo actuales pueden tener cientos de capas y miles de millones de parámetros, entrenados con conjuntos de datos masivos usando potentes GPUs. Esto habilita tecnologías como:
* GPT-4 y otros Modelos de Lenguaje Grandes (LLM)
* DALL·E y Midjourney para generación de imágenes
* AlphaFold para predicción de estructuras de proteínas
________________

SECCIÓN 2: El Perceptrón: El Bloque Fundamental
Páginas 4-6 | Tiempo de lectura: 6 minutos
2.1 Entendiendo el Perceptrón
El perceptrón es la forma más simple de red neuronal artificial: una sola neurona artificial. A pesar de su simplicidad, entenderlo es crucial porque las redes modernas no son más que millones de perceptrones trabajando en conjunto.

Anatomía de un Perceptrón
Un perceptrón tiene cuatro componentes esenciales:
1. Entradas (x₁, x₂, x₃, …, xₙ)
2. Pesos (w₁, w₂, w₃, …, wₙ) que determinan la importancia de cada entrada
3. Sesgo (bias): Parámetro adicional que desplaza el límite de decisión
4. Función de Activación: Decide si la neurona “dispara” según la suma ponderada

Fórmula Matemática
El perceptrón realiza un cálculo simple:
Paso 1: Multiplicar cada entrada por su peso correspondiente
* x₁ × w₁, x₂ × w₂, x₃ × w₃, etc.
Paso 2: Sumar todos esos productos y añadir el sesgo
* z = (x₁ × w₁) + (x₂ × w₂) + (x₃ × w₃) + … + bias
Paso 3: Aplicar una función de activación para determinar la salida
* salida = función_de_activación(z)

2.2 Un Ejemplo Concreto: Detección de Spam en Emails
Veamos cómo un perceptrón podría clasificar un email como spam o legítimo.
Escenario: Construir un filtro de spam simple
Entradas (Características):
* x₁ = Número de veces que aparece “FREE” (ej.: 3)
* x₂ = Número de signos de exclamación (ej.: 5)
* x₃ = ¿El remitente está en contactos? (0 = No, 1 = Sí; ej.: 0)
Pesos Aprendidos (tras el entrenamiento):
* w₁ = 0.4 (cada “FREE” aumenta la probabilidad de spam)
* w₂ = 0.3 (cada “!” aumenta la probabilidad de spam)
* w₃ = -0.8 (remitente conocido reduce probabilidad de spam)
Sesgo: -1.5 (umbral inicial)
Cálculo:
z = (3 × 0.4) + (5 × 0.3) + (0 × -0.8) + (-1.5) = 1.2

Función de Activación Escalón:
* Si z > 0: Salida = 1 (SPAM)
* Si z ≤ 0: Salida = 0 (LEGÍTIMO)
Resultado: Como z = 1.2 > 0, el email se clasifica como SPAM

2.3 Cómo Aprende un Perceptrón
La belleza del perceptrón es que puede aprender los pesos correctos automáticamente mediante entrenamiento:
Algoritmo de Entrenamiento:
1. Inicializar: Empezar con pesos aleatorios
2. Predecir: Usar los pesos actuales para clasificar un ejemplo
3. Calcular error: Comparar la predicción con la etiqueta real
4. Actualizar pesos: Ajustar en la dirección que reduce el error
5. Repetir: Iterar con más ejemplos hasta lograr buen desempeño

Regla de Actualización de Pesos:
nuevo_peso = peso_antiguo + (tasa_de_aprendizaje × error × entrada)

Ejemplo de Aprendizaje:
* Predicción: Email clasificado como LEGÍTIMO (0)
* Etiqueta Real: En realidad es SPAM (1)
* Error: 1 - 0 = 1
* Ajuste: Aumentar los pesos de las características presentes (como “FREE”)

Tras miles de ejemplos, el perceptrón aprende los pesos que mejor separan spam de legítimos.

2.4 Limitaciones del Perceptrón
Un solo perceptrón es potente para problemas simples, pero tiene límites:
Puede Resolver (Linealmente Separables):
* Puertas lógicas AND, OR
* Clasificación binaria con límite de decisión lineal
No Puede Resolver (No Linealmente Separables):
* Puerta XOR (exclusiva)
* Patrones que requieren fronteras curvas
* Problemas donde las clases están entremezcladas

Nota Histórica: El problema XOR, señalado en 1969 por Marvin Minsky y Seymour Papert, condujo al primer invierno de la IA. La solución: añadir más capas, creando redes multicapa (lo veremos enseguida).
________________

SECCIÓN 3: Funciones de Activación: Las Tomadoras de Decisiones
Páginas 7-9 | Tiempo de lectura: 6 minutos
3.1 ¿Qué son las Funciones de Activación?
Una función de activación es una función matemática aplicada a la suma ponderada de entradas en una neurona. Determina si y con qué intensidad la neurona debe “disparar”, introduciendo no linealidad en la red.

Por qué Importa la No Linealidad: Sin funciones de activación, incluso una red con muchas capas se comportaría como una red de una sola capa (la composición de funciones lineales sigue siendo lineal). Las funciones de activación permiten aprender patrones complejos no lineales.

3.2 Funciones de Activación Comunes
3.2.1 Función Escalón
La Original: Usada en el perceptrón clásico
Cómo funciona:
* Si entrada ≥ 0: salida = 1
* Si entrada < 0: salida = 0
Ventajas: Simple e intuitiva; decisiones binarias claras
Desventajas: No diferenciable; no indica “confianza”; poco usada hoy

3.2.2 Función Sigmoide
Fórmula: σ(z) = 1 / (1 + e^(-z))
Rango de salida: (0, 1)
Ventajas: Suave y diferenciable; interpretable como probabilidad
Desventajas: Gradiente que se desvanece; costosa computacionalmente; no centrada en cero
Usos comunes: Capa de salida en clasificación binaria

3.2.3 Tangente Hiperbólica (tanh)
Fórmula: tanh(z) = (e^z - e^(-z)) / (e^z + e^(-z))
Rango de salida: (-1, 1) (centrada en cero)
Ventajas: Salidas centradas; gradientes más fuertes que sigmoide
Desventajas: También sufre gradientes que se desvanecen
Usos: RNNs, cuando los datos están centrados en cero

3.2.4 ReLU (Unidad Lineal Rectificada)
Fórmula: ReLU(z) = max(0, z)
Rango de salida: [0, ∞)
Ventajas: Muy eficiente; mitiga gradientes que se desvanecen; activación dispersa
Desventajas: “ReLUs muertas” (salida cero constante) si reciben entradas negativas frecuentes
Usos: Capas ocultas en redes modernas; CNNs

3.2.5 Leaky ReLU
Fórmula: Leaky ReLU(z) = max(αz, z) (α típico: 0.01)
Ventaja: Permite pequeños gradientes para entradas negativas, evitando neuronas muertas
Variantes: PReLU (coeficiente aprendido)

3.3 Cómo Elegir la Función de Activación
Guías Generales:
* Capas ocultas: ReLU por defecto; si hay neuronas muertas → Leaky ReLU/PReLU
* RNNs: tanh o compuertas especializadas (LSTM, GRU)
* Capa de salida: Binaria → Sigmoide; Multiclase → Softmax; Regresión → Lineal/ReLU

Tendencias Modernas: Swish, GELU (transformers), Mish.
Idea Clave: La función de activación da a la red el poder para aprender patrones complejos; elegirla bien impacta el rendimiento.
________________

SECCIÓN 4: Redes Multicapa: Profundizando
Páginas 10-12 | Tiempo de lectura: 6 minutos
4.1 De una Sola Neurona a Redes Neuronales
El gran salto vino de conectar muchos perceptrones en capas, creando perceptrones multicapa (MLP) o redes feedforward.

Arquitectura de Red
Tres tipos de capas:
1. Capa de Entrada: Recibe los datos crudos; una neurona por característica
2. Capas Ocultas: Procesamiento intermedio; extraen características cada vez más complejas
3. Capa de Salida: Produce la predicción final (binaria, multiclase o regresión)

4.2 Flujo de Información (Forward Pass)
Paso a paso:
1) Capa de entrada: entra el dato crudo (p. ej., píxeles)
2) 1ª capa oculta: suma ponderada + sesgo → activación → salida a la siguiente capa
3) Capas ocultas siguientes: repiten el proceso extrayendo características más abstractas
4) Capa de salida: genera la predicción final con la activación adecuada

Ejemplo: Reconocimiento de dígitos escritos a mano (MNIST)
* Entrada (784): valores de píxel 28×28
* Oculta 1 (128): detecta bordes verticales/horizontales/diagonales, curvas
* Oculta 2 (64): combina patrones simples en componentes de dígitos
* Salida (10): una neurona por dígito 0-9; la de mayor puntuación es la predicción

4.3 El Poder de la Profundidad
¿Qué hace “profunda” a una red? 2+ capas ocultas (hoy pueden ser decenas o cientos).
¿Por qué más profunda?
* Jerarquía de características: baja (bordes) → media (formas) → alta (objetos/conceptos)
* Evidencia empírica: las redes profundas suelen generalizar mejor y ser más eficientes

4.4 Topología y Decisiones de Diseño
* Número de capas ocultas: 1 (simple), 2-3 (comunes), 4+ (problemas complejos), 50-200 (arquitecturas especializadas)
* Neuronas por capa: muy pocas → infraajuste; demasiadas → sobreajuste
  Ejemplo típico: 784 → 256 → 128 → 64 → 10
* Patrones de conectividad: densas (fully connected), convolucionales (visuales), recurrentes (secuencias)

4.5 Teorema de Aproximación Universal
Una red feedforward con al menos una capa oculta, suficientes neuronas y activación no lineal puede aproximar cualquier función continua con precisión arbitraria.
Implicación: En teoría, las redes pueden aprender cualquier patrón; en la práctica, hay que hallar la arquitectura y el entrenamiento adecuados.
________________

SECCIÓN 5: Cómo Aprenden las Redes: Retropropagación
Páginas 13-15 | Tiempo de lectura: 6 minutos
5.1 El Problema del Aprendizaje
Una red con pesos aleatorios hace predicciones aleatorias. Aprender significa ajustar los pesos para que las predicciones se acerquen a las etiquetas reales.

5.2 Entendiendo la Retropropagación
La retropropagación calcula eficientemente cuánto contribuyó cada peso al error, permitiendo actualizar en la dirección que reduce la pérdida.
Nombre: “Propagación hacia atrás del error” (desde la salida hacia la entrada).

Proceso de Entrenamiento (4 pasos)
1) Paso hacia adelante: calcular salidas y almacenar intermedios
2) Calcular pérdida: comparar con etiqueta real (MSE, entropía cruzada)
3) Paso hacia atrás: propagar gradientes usando la regla de la cadena; obtener ∂Loss/∂peso
4) Actualizar pesos: nuevo = viejo − (tasa_aprendizaje × gradiente)

Ejemplo Simplificado: Predicción de precio de vivienda
* Entrada: 2000 ft²; Precio real: $400,000; Predicción inicial: $700,000 → gran error
* Gradientes indican “reducir” salidas de neuronas que más contribuyeron
* Ajustes de pesos (w1, w2, w3, w4) disminuyen la predicción
* Repetir muchas veces → el modelo aprende

5.4 Matemáticas Detrás: Regla de la Cadena
∂Loss/∂w₁ = (∂Loss/∂Salida) × (∂Salida/∂Oculta) × (∂Oculta/∂w₁)
La retropropagación reutiliza cálculos intermedios, haciendo viable entrenar redes profundas.

5.5 Descenso de Gradiente
Usa los gradientes para actualizar pesos.
Analogía: Bajar una montaña con los ojos vendados siguiendo la pendiente.
* Tasa de aprendizaje pequeña: lento
* Grande: inestable
* Adecuada (p. ej., 0.001-0.01): progreso estable

Variantes:
* Batch: todo el dataset por actualización (preciso, lento)
* SGD: un ejemplo por actualización (rápido, ruidoso)
* Mini-batch (estándar): lotes de 32-256
* Optimizadores avanzados: Adam (muy usado), RMSprop, AdaGrad

5.6 Retos Comunes
* Gradientes que se desvanecen: usar ReLU, conexiones residuales, batch norm
* Gradientes explosivos: “clipping”, inicialización cuidadosa
* Mínimos locales: menos problemáticos de lo pensado; el ruido de SGD ayuda
________________

SECCIÓN 6: Aprendizaje Profundo en la Práctica
Páginas 16-18 | Tiempo de lectura: 6 minutos
6.1 ¿Qué hace “profundo” al aprendizaje?
Redes con múltiples capas ocultas (3+).

Hitos:
* Pre-2012: 2-3 capas
* 2012→: decenas/cientos de capas
* LLMs modernos: arquitecturas equivalentes a miles de “bloques”

Tres habilitadores:
1) Potencia de cómputo (GPUs, nube)
2) Disponibilidad de datos (ImageNet, Common Crawl)
3) Innovaciones algorítmicas (ReLU, dropout, batch norm, conexiones residuales)

6.2 Entrenando una Red Profunda: Pipeline Completo (ej. MNIST)
Fase 1: Datos
* Recolectar y etiquetar; dividir en train (70%), validación (15%), prueba (15%)
* Normalizar (0-1); aumento de datos (rotar, voltear, etc.)

Fase 2: Diseño
* Entrada: 784
* Oculta 1: 256 ReLU
* Oculta 2: 128 ReLU
* Oculta 3: 64 ReLU
* Salida: 10 Softmax
≈ 242,762 parámetros

Fase 3: Configuración
* Pérdida: entropía cruzada categórica
* Optimizador: Adam (lr=0.001)
* Batch: 64; Épocas: 20-50; early stopping por validación

Fase 4: Bucle de Entrenamiento
Para cada batch: forward → pérdida → backward → actualización
Al final de cada época: evaluar validación; si sube la pérdida → detener

Progreso típico:
Época 1: 87% / 85%
Época 10: 98% / 96%
Época 20: 99.5% / 97% (parar aquí por sobreajuste potencial)

Fase 5: Evaluación y Despliegue
* Evaluación final en prueba: ~97.2%
* Análisis de errores (matriz de confusión)
* Guardar pesos, integrar y monitorizar

6.3 Regularización
* Dropout: apagar aleatoriamente neuronas en entrenamiento (p. ej., 0.5)
* L2 (weight decay): penalizar pesos grandes
* Batch Normalization: estabiliza y acelera; ligera regularización
* Early Stopping: detener cuando validación deja de mejorar
* Aumento de Datos: rotar, recortar, brillo; para texto, sinónimos, back-translation

6.4 Ajuste de Hiperparámetros
Críticos:
1) Tasa de aprendizaje (0.0001–0.01)
2) Tamaño de lote (32–256)
3) Nº de capas y neuronas
4) Tasa de dropout (0.2–0.5)
5) Optimizador (Adam por defecto; SGD+momento a veces mejor al final)

Estrategia:
* Empezar con valores por defecto
* Entrenar baseline y diagnosticar (sobre/infraajuste)
* Cambiar una cosa a la vez, validar y registrar
* Schedulers de LR (decay, reducción por estancamiento)

6.5 Mejores Prácticas
* Empezar simple; iterar rápido; monitorizar pérdidas y métricas
* Depurar sistemáticamente (curvas de train/val)
* Usar transferencia de aprendizaje cuando sea posible
* Evitar: datos sin verificar, probar en train, ignorar validación, complejidad excesiva, no normalizar, “mirar” el test durante el desarrollo
________________

SECCIÓN 7: Aplicaciones en el Mundo Real
Páginas 19-20 | Tiempo de lectura: 6 minutos
7.1 Visión por Computador
Reconocimiento de Dígitos (MNIST)
* 70,000 imágenes 28×28 de dígitos (60k train, 10k test)
Arquitectura simple: 784 → 128 (ReLU) → Dropout 0.2 → 64 (ReLU) → Dropout 0.2 → 10 (Softmax)
Resultados:
* Red densa simple: ~97%
* CNN: ~99.5%

Más allá de MNIST: imágenes médicas, vehículos autónomos, seguridad, agricultura.
ImageNet (2012): AlexNet logró un salto del 10% en precisión, detonando la revolución del deep learning.

7.2 Procesamiento de Lenguaje Natural (PLN)
De Palabras a Números
* One-hot: vectores dispersos sin relaciones
* Embeddings: vectores densos que capturan semántica (gato/perro similares)

Clasificación de Sentimientos
* Embedding → LSTM/GRU → Densa ReLU → Sigmoide
Impacto: análisis de reseñas, monitoreo de marca, investigación de mercado.

7.3 Salud
Análisis de Imágenes Médicas
* Retinopatía diabética, cáncer: desempeño comparable o superior al humano en algunos estudios
* Consideraciones: transparencia, validación amplia, regulación (FDA), humano en el bucle

Descubrimiento de Fármacos
* Predicción de propiedades moleculares, plegamiento de proteínas (AlphaFold), interacción fármaco-objetivo
* Reducción de costos y tiempos tempranos

7.4 Sistemas Autónomos
Autos Autónomos: detección, segmentación, profundidad, predicción de trayectorias, planeación
Retos: seguridad, tiempo real, condiciones diversas, explicabilidad
Estado actual (2025): Niveles 2-3 extendidos; 4-5 en zonas geocercadas

Robótica: picking, inspección, ensamblaje; logística, limpieza, reparto

7.5 Aplicaciones Creativas
Generación de Imágenes
* GANs: generador vs discriminador
* Modelos de difusión: texto-a-imagen (p. ej., “un gato con sombrero de copa”)

Música y Audio: composición automática; síntesis de voz natural
Asistencia de Escritura: LLMs (GPT-4, etc.) para redacción, código, análisis

7.6 El Futuro
Tendencias: modelos multimodales, few-shot, búsqueda de arquitecturas automáticas, eficiencia energética (edge), IA explicable
Desafíos: sesgo y equidad, privacidad, robustez (ataques adversarios), generalización, alineamiento

7.7 Resumen: La Revolución de las Redes Neuronales
Logros: desempeño superhumano en visión, PLN avanzado, apoyo al diagnóstico, sistemas autónomos, herramientas creativas
Principios: aprendizaje jerárquico, de extremo a extremo, escalabilidad, generalización (transfer learning)
Mirando Adelante: el progreso es acelerado; lo “imposible” de hace una década hoy es común.
Tu Papel: Entender redes neuronales ya es esencial para profesionales tecnológicos.

________________

Resumen del Módulo 3: Puntos Clave
Conceptos Dominados:
1) Biológico a Artificial: las redes imitan estructura cerebral—neuronas, conexiones, aprendizaje por ajuste
2) Perceptrón: neurona artificial más simple—suma ponderada + sesgo + activación
3) Funciones de Activación: introducen no linealidad (Escalón, Sigmoide, tanh, ReLU)
4) Redes Multicapa: apilar capas para jerarquía—entrada → ocultas → salida
5) Retropropagación: cálculo eficiente de gradientes—viabiliza el entrenamiento profundo
6) Aprendizaje Profundo: muchas capas → representaciones jerárquicas—revolucionó la IA
7) Proceso de Entrenamiento: forward → pérdida → backward → actualización → repetir
8) Regularización: prevenir sobreajuste—dropout, decaimiento de pesos, early stopping
9) Impacto Real: visión, PLN, salud, sistemas autónomos, creatividad

Glosario en Español:
* Red Neuronal = Neural Network
* Perceptrón = Perceptron
* Función de Activación = Activation Function
* Capa Oculta = Hidden Layer
* Retropropagación = Backpropagation
* Aprendizaje Profundo = Deep Learning
* Descenso de Gradiente = Gradient Descent
* Función de Pérdida = Loss Function
* Sobreajuste = Overfitting
* Regularización = Regularization

Próximos Pasos:
El Módulo 4 explorará IA Generativa y Modelos de Lenguaje Grandes—la vanguardia que está transformando cómo interactuamos con sistemas de IA.
Prepárate:
* Completa la simulación interactiva del perceptrón
* Revisa el ejemplo de MNIST
* Intenta las preguntas de práctica

________________

Fin del Material de Lectura | Total de Páginas: 20 | Tiempo de Lectura: 48 minutos
________________

Recursos Adicionales
De la Librería del Curso:
1) Microsoft AI for Beginners — tutoriales completos con laboratorios
2) Curso de Aprendizaje Automático de Andrew Ng — profundización matemática en retropropagación
3) Deep Learning Specialization (deeplearning.ai) — conceptos avanzados en arquitecturas neuronales

Orden de Lectura Recomendado:
1) Completar este material
2) Realizar la simulación interactiva
3) Resolver problemas de práctica
4) Explorar recursos externos según tus dudas
5) Completar el cuestionario del módulo

Sugerencias de Práctica:
* Bosqueja arquitecturas a mano
* Calcula forward y backward manualmente en redes diminutas
* Implementa un perceptrón simple desde cero
* Analiza curvas de aprendizaje de los ejemplos

________________

Este material está diseñado para el curso de 20 horas de la Plataforma MTW AI. El Módulo 3 se apoya en los fundamentos de los Módulos 1-2 y te prepara para temas avanzados en los Módulos 4-10.
